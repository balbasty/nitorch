#include <ATen/ATen.h>
#include <vector>
#include "defines.h"
#include "bounds.h"
#include "resize.h"
#include "relax.h"
#include "relax_grid.h"
#include "regulariser.h"
#include "regulariser_grid.h"

using c10::IntArrayRef;
using at::Tensor;

namespace ni {

namespace {

  inline Tensor init_solution(const Tensor & solution, const Tensor & gradient)
  {
    if (solution.defined() && solution.numel() > 0)
      return solution;
    return at::zeros_like(gradient);
  }

  inline Tensor dot(Tensor a, Tensor b)
  {
    int64_t dim = a.dim() - 2;
    a = a.reshape({a.size(0), 1, -1});
    b = b.reshape({b.size(0), -1, 1});
    a = at::matmul(a, b)
    for (d = 0; d < dim; ++d) a = a.unsqueeze(-1);
    return a
  }

  template <typename ForwardFn, typename PrecondFn>
  inline void do_pcg(const Tensor & h, const Tensor & g, 
                     Tensor & x, const Tensor & w,
                     int64_t nb_iter, ForwardFn forward, PrecondFn precond)
  {
      Tensor alpha, beta, rz, rz0; // "scalar" tensors (can have a batch dim)
      Tensor r = at::empty_like(g), z = at::empty_like(g);

      // Initialisation
      forward(h, x, w, r);       // r  = (H + KWK) * x
      at::sub_out(r, g, r);      // r  = g - r
      precond(h, r, w, z);       // z  = (H + diag(W)) \ r
      rz = dot(r, z)             // rz = r' * z
      Tensor p = z.clone()       // Initial conjugate directions p

      for (n = 0;  n < nb_iter; ++n)
      {
        forward(h, p, w, z);                      // Ap = (H + KWK) * p
        alpha = dot(p, Ap);                       // alpha = p' * Ap
        alpha = rz / at::clamp_min(alpha, 1e-12)  // alpha = (r' * z) / (p' * Ap)
        at::addcmul_out(x, x, p, alpha);          // x += alpha * p
        at::addcmul_out(r, r, z, alpha, -1);      // r -= alpha * Ap
        precond(h, r, w, z);                      // z  = (H + diag(W)) \ r
        rz0 = rz
        rz = dot(r, z)
        beta = rz / at::clamp_min_(rz0, 1e-12)
        at::addcmul_out(p, z, p, beta);           // p = z + beta * p
      }
  }

}


Tensor pcg(const Tensor & hessian, 
           const Tensor & gradient,
           Tensor solution,
           const Tensor & weight,
           const vector<double> &  absolute, 
           const vector<double> &  membrane, 
           const vector<double> &  bending,
           const vector<double> &  voxel_size, 
           const vector<BoundType> & bound,
           int64_t nb_iter)
{

  /* ---------------- function handles ---------------------- */
  auto forward_ = [absolute, membrane, bending, bound, voxel_size]
                  (const Tensor & hessian, const Tensor & input,
                   const Tensor & weight,  const Tensor & output)
  {
    regulariser(input, output, weight, hessian,
                absolute, membrane, bending, voxel_size, bound);
  };
  auto precond = [absolute, membrane, bending, bound, voxel_size, nb_iter]
                (const Tensor & hessian, const Tensor & gradient,
                 const Tensor & solution, const Tensor & weight)
  {
    relax(hessian, gradient, solution, weight, 
          absolute, membrane, bending, voxel_size, bound, nb_iter);
  };


  /* ---------------- initialize pyramid -------------------- */
  solution = init_solution(solution, gradient);
  vector<Tensor> tensors(max_levels*5);
  int64_t N = prepare_tensors(hessian, gradient, solution, weight, 
                              tensors.data(), restrict_, restrict_, 
                              max_levels);
  Tensor * h = tensors.data();
  Tensor * g = h + max_levels;
  Tensor * x = g + max_levels;
  Tensor * w = x + max_levels;
  Tensor * r = w + max_levels;

  /* ------------------------ FMG algorithm ------------------ */
  do_fmg(h, g, x, w, r, N, nb_cycles, 
         relax_, prolong_, restrict_, residuals_);

  return solution;
}

}
