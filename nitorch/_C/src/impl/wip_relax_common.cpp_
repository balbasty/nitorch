#include "common.h"
#include "bounds_common.h"
#include "allocator.h"
#include <ATen/ATen.h>
#include <limits>
#include <cmath>
//#include <cstdio>

// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
// CPU/GPU -specific parameters
#ifdef __CUDACC__
# include <ATen/cuda/CUDAContext.h>
# include <ATen/cuda/detail/KernelUtils.h>
# include <c10/macros/Macros.h>
  using namespace at::cuda::detail;
#else
# include <ATen/Parallel.h>
  namespace {
    // This parameter specifies the minimum number of voxels that should be
    // processed on a single processor in the parallel for loop .
    int64_t GRAIN_SIZE = static_cast<int64_t>(at::internal::GRAIN_SIZE);
  }
#endif
// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

using at::Tensor;
using at::TensorOptions;
using c10::IntArrayRef;
using c10::ArrayRef;

// Required for stability. Value is currently about 1+8*eps
#define OnePlusTiny 1.000001

// Macro to cleanly invoke a pointer to member function
#define CALL_MEMBER_FN(object,ptrToMember)  ((object).*(ptrToMember))
#define MIN(a,b) (a < b ? a : b)
#define MAX(a,b) (a < b ? b : a)

#ifndef NI_MAX_NUM_CHANNELS
# define NI_MAX_NUM_CHANNELS 1024
#endif

namespace ni {
NI_NAMESPACE_DEVICE { // cpu / cuda / ...

namespace { // anonymous namespace > everything inside has internal linkage


class RelaxAllocator: public Allocator {
public:

  static constexpr int64_t max_int32 = std::numeric_limits<int32_t>::max();

  // ~~~ CONSTRUCTOR ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

  NI_HOST
  RelaxAllocator(int dim, bool grid,
                 double absolute, double membrane, double bending,
                 double lame_shear, double lame_div,
                 ArrayRef<double> factor, ArrayRef<double> voxel_size,
                 BoundVectorRef bound):
    dim(dim),
    bound0(bound.size() > 0 ? bound[0] : BoundType::Replicate),
    bound1(bound.size() > 1 ? bound[1] :
           bound.size() > 0 ? bound[0] : BoundType::Replicate),
    bound2(bound.size() > 2 ? bound[2] :
           bound.size() > 1 ? bound[1] :
           bound.size() > 0 ? bound[0] : BoundType::Replicate),
    vx0(voxel_size.size() > 0 ? voxel_size[0] : 1.),
    vx1(voxel_size.size() > 1 ? voxel_size[1] :
        voxel_size.size() > 0 ? voxel_size[0] : 1.),
    vx2(voxel_size.size() > 2 ? voxel_size[2] :
        voxel_size.size() > 1 ? voxel_size[1] :
        voxel_size.size() > 0 ? voxel_size[0] : 1.),
    f0(factor.size() > 0 ? factor[0] : 1.),
    f1(factor.size() > 1 ? factor[1] :
       factor.size() > 0 ? factor[0] : 1.),
    f2(factor.size() > 2 ? factor[2] :
       factor.size() > 1 ? factor[1] :
       factor.size() > 0 ? factor[0] : 1.),
    absolute(absolute),
    membrane(membrane),
    bending(bending),
    lame_shear(lame_shear),
    lame_div(lame_div),
    factor(factor),
    grid(grid)
  {
    vx0 *= vx0;
    vx1 *= vx1;
    vx2 *= vx2;
    if (grid)
    {
      f0 *= vx0;
      f1 *= vx1;
      f2 *= vx2;
      factor = ArrayRef<double>({f0, f1, f2});
    }
    else if (factor.size() == 0)
      factor = ArrayRef<double>({f0});
    vx0 = 1. / vx0;
    vx1 = 1. / vx1;
    vx2 = 1. / vx2;
  }

  // ~~~ FUNCTORS ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

  NI_HOST void ioset
  (const Tensor& hess, const Tensor& grad,
   const Tensor& solution, const Tensor& weight)
  {
    init_all();
    init_hessian(hess);
    init_gradient(grad);
    init_solution(solution);
    init_weight(weight);
  }

  // We just check that all tensors that we own are compatible with 32b math
  bool canUse32BitIndexMath(int64_t max_elem=max_int32) const
  {
    return hes_32b_ok && grd_32b_ok && wgt_32b_ok && sol_32b_ok;
  }

private:

  // ~~~ COMPONENTS ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  NI_HOST void init_all();
  NI_HOST void init_hessian(const Tensor&);
  NI_HOST void init_gradient(const Tensor&);
  NI_HOST void init_solution(const Tensor&);
  NI_HOST void init_weight(const Tensor&);

  // ~~~ OPTIONS ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  int               dim;            // dimensionality (2 || 3)
  BoundType         bound0;         // boundary condition  // x|W
  BoundType         bound1;         // boundary condition  // y|H
  BoundType         bound2;         // boundary condition  // z|D
  double            vx0;            // voxel size // x|W
  double            vx1;            // voxel size // y|H
  double            vx2;            // voxel size // z|D
  double            f0;             // factor (grid only) // x|W
  double            f1;             // factor (grid only) // y|H
  double            f2;             // factor (grid only) // z|D
  double            absolute;       // penalty on absolute values
  double            membrane;       // penalty on first derivatives
  double            bending;        // penalty on second derivatives
  double            lame_shear;     // penalty on symmetric part of Jacobian
  double            lame_div;       // penalty on trace of Jacobian
  ArrayRef<double>  factor;         // Modulating factor per channel
  bool              grid;           // Displacement field mode

  // ~~~ NAVIGATORS ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

#define DEFINE_ALLOC_INFO_5D(NAME)  \
  TensorOptions ##NAME##_opt;       \
  int64_t ##NAME##_sN;              \
  int64_t ##NAME##_sC;              \
  int64_t ##NAME##_sX;              \
  int64_t ##NAME##_sY;              \
  int64_t ##NAME##_sZ;              \
  bool ##NAME##_32b_ok;             \
  void *##NAME##_ptr;

  int64_t N;
  int64_t C;
  int64_t CC;
  int64_t X;
  int64_t Y;
  int64_t Z;
  DEFINE_ALLOC_INFO_5D(hes)
  DEFINE_ALLOC_INFO_5D(grd)
  DEFINE_ALLOC_INFO_5D(sol)
  DEFINE_ALLOC_INFO_5D(wgt)

  // Allow RelaxImpl's constructor to access RelaxAllocator's
  // private members.
  template <typename scalar_t, typename offset_t>
  friend class RelaxImpl;
};


NI_HOST
void RelaxAllocator::init_all()
{
  hes_opt = TensorOptions();
  grd_opt = TensorOptions();
  sol_opt = TensorOptions();
  wgt_opt = TensorOptions();
  N = C = CC = X = Y = Z = 1L;
  hes_sN  = hes_sC   = hes_sX   = hes_sY  = hes_sZ   = 0L;
  grd_sN  = grd_sC   = grd_sX   = grd_sY  = grd_sZ   = 0L;
  sol_sN  = sol_sC   = sol_sX   = sol_sY  = sol_sZ   = 0L;
  wgt_sN  = wgt_sC   = wgt_sX   = wgt_sY  = wgt_sZ   = 0L;
  hes_ptr = grd_ptr = sol_ptr = wgt_ptr = static_cast<float*>(0);
  hes_32b_ok = grd_32b_ok = sol_32b_ok = wgt_32b_ok = true;
}

NI_HOST
void RelaxAllocator::init_hessian(const Tensor& input)
{
  if (!input.defined() || input.numel() == 0)
    return
  CC      = input.size(1);
  hes_sN  = input.stride(0);
  hes_sC  = input.stride(1);
  hes_sX  = input.stride(2);
  hes_sY  = dim < 2 ? 0L : input.stride(3);
  hes_sZ  = dim < 3 ? 0L : input.stride(4);
  hes_ptr = input.data_ptr();
  hes_opt = input.options();
  hes_32b_ok = tensorCanUse32BitIndexMath(input);
}

NI_HOST
void RelaxAllocator::init_gradient(const Tensor& input)
{
  N       = input.size(0);
  C       = input.size(1);
  X       = input.size(2);
  Y       = dim < 2 ? 1L : input.size(3);
  Z       = dim < 3 ? 1L : input.size(4);
  grd_sN  = input.stride(0);
  grd_sC  = input.stride(1);
  grd_sX  = input.stride(2);
  grd_sY  = dim < 2 ? 0L : input.stride(3);
  grd_sZ  = dim < 3 ? 0L : input.stride(4);
  grd_ptr = input.data_ptr();
  grd_opt = input.options();
  grd_32b_ok = tensorCanUse32BitIndexMath(input);
}

NI_HOST
void RelaxAllocator::init_solution(const Tensor& input)
{
  sol_sN  = input.stride(0);
  sol_sC  = input.stride(1);
  sol_sX  = input.stride(2);
  sol_sY  = dim < 2 ? 0L : input.stride(3);
  sol_sZ  = dim < 3 ? 0L : input.stride(4);
  sol_ptr = input.data_ptr();
  sol_opt = input.options();
  sol_32b_ok = tensorCanUse32BitIndexMath(input);
  output = input;
}

NI_HOST
void RelaxAllocator::init_weight(const Tensor& weight)
{
  if (!input.defined() || input.numel() == 0)
    return
  wgt_sN  = weight.stride(0);
  wgt_sC  = weight.stride(1);
  wgt_sX  = weight.stride(2);
  wgt_sY  = dim < 2 ? 0L : weight.stride(3);
  wgt_sZ  = dim < 3 ? 0L : weight.stride(4);
  wgt_ptr = weight.data_ptr();
  wgt_opt = weight.options();
  wgt_32b_ok = tensorCanUse32BitIndexMath(weight);
}

template <typename scalar_t, typename offset_t>
class RelaxImpl {
  typedef RelaxImpl Self;
  typedef void (Self::*RelaxFn)(offset_t x, offset_t y, offset_t z, offset_t n) const;
  typedef void (Self::*InvertFn)(scalar_t *x, double *h, double *v, double *k) const;
  typedef void (Self::*GetHFn)(scalar_t *, double *) const;
public:

  // ~~~ CONSTRUCTOR ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  RelaxImpl(const RelaxAllocator & info):
    output(info.output),
    dim(info.dim),
    bound0(info.bound0), bound1(info.bound1), bound2(info.bound2),
    vx0(info.vx0), vx1(info.vx1), vx2(info.vx2),
    f0(info.f0), f1(info.f1), f2(info.f2),
    absolute(info.absolute), membrane(info.membrane), bending(info.bending),
    lame_shear(info.lame_shear), lame_div(info.lame_div),
    factor(info.factor), grid(info.grid),
    N(static_cast<offset_t>(info.N)),
    C(static_cast<offset_t>(info.C)),
    CC(static_cast<offset_t>(info.CC)),
    X(static_cast<offset_t>(info.X)),
    Y(static_cast<offset_t>(info.Y)),
    Z(static_cast<offset_t>(info.Z)),

#define INIT_ALLOC_INFO_5D(NAME) \
    NAME##_sN(static_cast<offset_t>(info.NAME##_sN)), \
    NAME##_sC(static_cast<offset_t>(info.NAME##_sC)), \
    NAME##_sX(static_cast<offset_t>(info.NAME##_sX)), \
    NAME##_sY(static_cast<offset_t>(info.NAME##_sY)), \
    NAME##_sZ(static_cast<offset_t>(info.NAME##_sZ)), \
    NAME##_ptr(static_cast<scalar_t*>(info.NAME##_ptr))

    INIT_ALLOC_INFO_5D(hes),
    INIT_ALLOC_INFO_5D(grd),
    INIT_ALLOC_INFO_5D(sol),
    INIT_ALLOC_INFO_5D(wgt)
  {

    double lam0 = absolute, lam1 = membrane, lam2 = bending,
           mu = lame_shear, lam = lame_div, v0 = vx0, v1 = vx1, v2 = vx2;

    w000 = lam2*(6.0*(v0*v0+v1*v1+v2*v2) + 8*(v0*v1+v0*v2+v1*v2)) + lam1*2*(v0+v1+v2) + lam0;
    w100 = lam2*(-4.0*v0*(v0+v1+v2)) -lam1*v0;
    w010 = lam2*(-4.0*v1*(v0+v1+v2)) -lam1*v1;
    w001 = lam2*(-4.0*v2*(v0+v1+v2)) -lam1*v2;
    w200 = lam2*v0*v0;
    w020 = lam2*v1*v1;
    w002 = lam2*v2*v2;
    w110 = lam2*2.0*v0*v1;
    w101 = lam2*2.0*v0*v2;
    w011 = lam2*2.0*v1*v2;

    wx000 =  2.0*mu*(2.0*v0+v1+v2)/v0+2.0*lam + w000/v0;
    wx100 = -2.0*mu-lam + w100/v0;
    wx010 = -mu*v1/v0 + w010/v0;
    wx001 = -mu*v2/v0 + w001/v0;
    wy000 =  2.0*mu*(v0+2.0*v1+v2)/v1+2.0*lam + w000/v1;
    wy100 = -mu*v0/v1 + w100/v1;
    wy010 = -2.0*mu-lam + w010/v1;
    wy001 = -mu*v2/v1 + w001/v1;
    wz000 =  2.0*mu*(v0+v1+2.0*v2)/v2+2.0*lam + w000/v2;
    wz100 = -mu*v0/v2 + w100/v2;
    wz010 = -mu*v1/v2 + w010/v2;
    wz001 = -2.0*mu-lam + w001/v2;
    w2    = 0.25*mu+0.25*lam;

    // TODO: correct for 1d/2d cases

    wx000 *= OnePlusTiny;
    wy000 *= OnePlusTiny;
    wz000 *= OnePlusTiny;

    if (wgt_ptr)
    {
      if (bending || lame_div || lame_shear)
        throw std::logic_error("RLS only implemented for absolute/membrane.");
      else if (dim == 1) {
        if (membrane)
            relax = &Self::relax1d_rls_membrane;
        else if (absolute)
            relax = &Self::relax1d_rls_absolute;
        else
            relax = &Self::copy1d;
      } else if (dim == 2) {
        if (membrane)
            relax = &Self::relax2d_rls_membrane;
        else if (absolute)
            relax = &Self::relax2d_rls_absolute;
        else
            relax = &Self::copy2d;
      } else if (dim == 3) {
        if (membrane)
            relax = &Self::relax3d_rls_membrane;
        else if (absolute)
            relax = &Self::relax3d_rls_absolute;
        else
            relax = &Self::copy3d;
      }
    }
    else if (dim == 1) {
        if ((lame_shear || lame_div) && bending)
            relax = &Self::relax1d_all;
        else if (lame_shear || lame_div)
            relax = &Self::relax1d_lame;
        else if (bending)
            relax = &Self::relax1d_bending;
        else if (membrane)
            relax = &Self::relax1d_membrane;
        else if (absolute)
            relax = &Self::relax1d_absolute;
        else
            relax = &Self::copy1d;
    } else if (dim == 2) {
        if ((lame_shear || lame_div) && bending)
            relax = &Self::relax2d_all;
        else if (lame_shear || lame_div)
            relax = &Self::relax2d_lame;
        else if (bending)
            relax = &Self::relax2d_bending;
        else if (membrane)
            relax = &Self::relax2d_membrane;
        else if (absolute)
            relax = &Self::relax2d_absolute;
        else
            relax = &Self::copy2d;
    } else if (dim == 3) {
        if ((lame_shear || lame_div) && bending)
            relax = &Self::relax3d_all;
        else if (lame_shear || lame_div)
            relax = &Self::relax3d_lame;
        else if (bending)
            relax = &Self::relax3d_bending;
        else if (membrane)
            relax = &Self::relax3d_membrane;
        else if (absolute)
            relax = &Self::relax3d_absolute;
        else
            relax = &Self::copy3d;
    } else
        throw std::logic_error("RLS only implemented for dimension 1/2/3.");

    if (bending)
        bandwidth = 3;
    else if (lame_shear || lame_div)
        bandwidth = 2;
    else if (membrane)
        bandwidth = 0; // checkerboard
    else
        bandwidth = 1;

    if (bandwidth)
    {
        // Size of the band in each direction
        Fx = MIN(X, bandwidth);
        Fy = MIN(Y, bandwidth);
        Fz = MIN(Z, bandwidth);

        // size of the fold
        Xf = (X + Fx - 1) / Fx;
        Yf = (Y + Fy - 1) / Fy;
        Zf = (Z + Fz - 1) / Fz;
    }

  if (hes_ptr) {
    if (CC == 1) {
        invert_and_matvec = matvec_and_invert_const;
        get_h = get_h_const;
    } else if (CC == C) {
        invert_and_matvec = matvec_and_invert_diag;
        get_h = get_h_diag;
    } else {
        invert_and_matvec = matvec_and_invert_sym;
        get_h = get_h_sym;
  } else {
    invert_and_matvec = matvec_and_invert_none;
    get_h = get_h_none;
  }

    // ~~~ FUNCTORS ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

#if __CUDACC__
  // Loop over voxels that belong to one CUDA block
  // This function is called by the CUDA kernel
  NI_DEVICE void loop(int threadIdx, int blockIdx,
                      int blockDim, int gridDim) const;
#else
  // Loop over all voxels
  void loop() const;
#endif

  NI_HOST NI_DEVICE int64_t voxcount() const {
    return N * X * Y * Z;
  }

  NI_HOST NI_DEVICE int64_t voxcountfold() const {
    return bandwidth == 0 ? voxcount() : N * Xf * Yf * Zf;
  }

  NI_HOST NI_DEVICE int64_t foldcount() const {
    return bandwidth == 0 ? 2 : Fx * Fy * Fz;
  }

  NI_HOST void set_fold(offset_t i) {
      // checkerboard
      if (bandwidth == 0)
        redblack = i;
        return
      // index of the fold (lin2sub)
      fx = i/(Fy*Fz);
      fy = (i/Fz)  % Y;
      fz = i % Z;
  }

  Tensor output;

private:

  // ~~~ COMPONENTS ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  NI_DEVICE void dispatch(
    offset_t x, offset_t y, offset_t z, offset_t n) const;

  NI_DEVICE void relax1d_absolute(
    offset_t x, offset_t y, offset_t z, offset_t n) const;
  NI_DEVICE void relax1d_membrane(
    offset_t x, offset_t y, offset_t z, offset_t n) const;
  NI_DEVICE void relax1d_bending(
    offset_t x, offset_t y, offset_t z, offset_t n) const;
  NI_DEVICE void relax1d_lame(
    offset_t x, offset_t y, offset_t z, offset_t n) const;
  NI_DEVICE void relax1d_all(
    offset_t x, offset_t y, offset_t z, offset_t n) const;
  NI_DEVICE void relax2d_absolute(
    offset_t x, offset_t y, offset_t z, offset_t n) const;
  NI_DEVICE void relax2d_membrane(
    offset_t x, offset_t y, offset_t z, offset_t n) const;
  NI_DEVICE void relax2d_bending(
    offset_t x, offset_t y, offset_t z, offset_t n) const;
  NI_DEVICE void relax2d_lame(
    offset_t x, offset_t y, offset_t z, offset_t n) const;
  NI_DEVICE void relax2d_all(
    offset_t x, offset_t y, offset_t z, offset_t n) const;
  NI_DEVICE void relax3d_absolute(
    offset_t x, offset_t y, offset_t z, offset_t n) const;
  NI_DEVICE void relax3d_membrane(
    offset_t x, offset_t y, offset_t z, offset_t n) const;
  NI_DEVICE void relax3d_bending(
    offset_t x, offset_t y, offset_t z, offset_t n) const;
  NI_DEVICE void relax3d_lame(
    offset_t x, offset_t y, offset_t z, offset_t n) const;
  NI_DEVICE void relax3d_all(
    offset_t x, offset_t y, offset_t z, offset_t n) const;

  // Reweighted versions
  NI_DEVICE void relax1d_rls_absolute(
    offset_t x, offset_t y, offset_t z, offset_t n) const;
  NI_DEVICE void relax1d_rls_membrane(
    offset_t x, offset_t y, offset_t z, offset_t n) const;
  NI_DEVICE void relax2d_rls_absolute(
    offset_t x, offset_t y, offset_t z, offset_t n) const;
  NI_DEVICE void relax2d_rls_membrane(
    offset_t x, offset_t y, offset_t z, offset_t n) const;
  NI_DEVICE void relax3d_rls_absolute(
    offset_t x, offset_t y, offset_t z, offset_t n) const;
  NI_DEVICE void relax3d_rls_membrane(
    offset_t x, offset_t y, offset_t z, offset_t n) const;

  NI_DEVICE void copy1d(
    offset_t x, offset_t y, offset_t z, offset_t n) const;
  NI_DEVICE void copy2d(
    offset_t x, offset_t y, offset_t z, offset_t n) const;
  NI_DEVICE void copy3d(
    offset_t x, offset_t y, offset_t z, offset_t n) const;

  NI_DEVICE void matvec_and_invert_sym(
    scalar_t * x, double * h, double * v, double * k) const;
  NI_DEVICE void matvec_and_invert_diag(
    scalar_t * x, double * h, double * v, double * k) const;
  NI_DEVICE void matvec_and_invert_const(
    scalar_t * x, double * h, double * v, double * k) const;
  NI_DEVICE void matvec_and_invert_none(
    scalar_t * x, double * h, double * v, double * k) const;

  NI_DEVICE void get_h_sym(scalar_t * x, double * h) const;
  NI_DEVICE void get_h_diag(scalar_t * x, double * h) const;
  NI_DEVICE void get_h_const(scalar_t * x, double * h) const;
  NI_DEVICE void get_h_none(scalar_t * x, double * h) const;

  // ~~~ OPTIONS ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  int               dim;            // dimensionality (2 || 3)
  BoundType         bound0;         // boundary condition  // x|W
  BoundType         bound1;         // boundary condition  // y|H
  BoundType         bound2;         // boundary condition  // z|D
  double            vx0;            // voxel size // x|W
  double            vx1;            // voxel size // y|H
  double            vx2;            // voxel size // z|D
  double            f0;             // factor (grid only) // x|W
  double            f1;             // factor (grid only) // y|H
  double            f2;             // factor (grid only) // z|D
  double            absolute;       // penalty on absolute values
  double            membrane;       // penalty on first derivatives
  double            bending;        // penalty on second derivatives
  double            lame_shear;     // penalty on symmetric part of Jacobian
  double            lame_div;       // penalty on trace of Jacobian
  ArrayRef<double>  factor;         // Modulating factor per channel
  bool              grid;           // Displacement field mode
  RelaxFn           relax;          // Pointer to relax function
  InvertFn          invert_and_matvec; // Pointer to inversion function
  GetHFn            get_h;          // Pointer to inversion function

  // ~~~ KERNEL ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

  // membrane/bending kernel
  double  w000;
  double  w100;
  double  w010;
  double  w001;
  double  w200;
  double  w020;
  double  w002;
  double  w110;
  double  w101;
  double  w011;

  // linear elastic kernel
  double  wx000;
  double  wx100;
  double  wx010;
  double  wx001;
  double  wy000;
  double  wy100;
  double  wy010;
  double  wy001;
  double  wz000;
  double  wz100;
  double  wz010;
  double  wz001;
  double  w2;

  // ~~~ FOLD NAVIGATORS ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

  offset_t Fx; // Fold window
  offset_t Fy;
  offset_t Fz;
  offset_t fx; // Index of the fold
  offset_t fy;
  offset_t fz;
  offset_t Xf; // Size of the fold
  offset_t Yf;
  offset_t Zf;
  offset_t redblack;  // Index of the fold for checkerboard scheme

  // ~~~ NAVIGATORS ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

  offset_t N;
  offset_t C;
  offset_t CC;
  offset_t X;
  offset_t Y;
  offset_t Z;

#define DEFINE_STRIDE_INFO_5D(NAME) \
  TensorOptions ##NAME##_opt;         \
  offset_t ##NAME##_sN;               \
  offset_t ##NAME##_sC;               \
  offset_t ##NAME##_sX;               \
  offset_t ##NAME##_sY;               \
  offset_t ##NAME##_sZ;               \
  scalar_t *##NAME##_ptr;

  DEFINE_STRIDE_INFO_5D(hes)
  DEFINE_STRIDE_INFO_5D(grd)
  DEFINE_STRIDE_INFO_5D(sol)
  DEFINE_STRIDE_INFO_5D(wgt)
};


// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
//                             LOOP
// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

template <typename scalar_t, typename offset_t> NI_DEVICE
void RelaxImpl<scalar_t,offset_t>::dispatch(
    offset_t x, offset_t y, offset_t z, offset_t n) const {
    CALL_MEMBER_FN(*this, relax)(x, y, z, n);
}

#if __CUDACC__

template <typename scalar_t, typename offset_t> NI_DEVICE
void RelaxImpl<scalar_t,offset_t>::loop(
  int threadIdx, int blockIdx, int blockDim, int gridDim) const {

  if (bandwidth == 0)
    return loop_redblack(threadIdx, blockIdx, blockDim, gridDim);
  else
    return loop_band(threadIdx, blockIdx, blockDim, gridDim);
}

template <typename scalar_t, typename offset_t> NI_DEVICE
void RelaxImpl<scalar_t,offset_t>::loop_band(
  int threadIdx, int blockIdx, int blockDim, int gridDim) const {

  int64_t index = blockIdx * blockDim + threadIdx;
  int64_t nthreads = N * Xf * Yf * Zf;
  offset_t YZf   = Yf * Zf;
  offset_t XYZf  = Xf * YZf;
  offset_t n, x, y, z;
  for (offset_t i=index; index < nthreads; index += blockDim*gridDim, i=index)
  {
      // Convert index: linear to sub
      n  = (i/XYZf);
      x  = ((i/YZf) % Xf) * Fx + fx;
      y  = ((i/Zf)  % Yf) * Fy + fy;
      z  = (i       % Zf) * Fz + fz;
      dispatch(x, y, z, n);
  }
}

template <typename scalar_t, typename offset_t> NI_DEVICE
void RelaxImpl<scalar_t,offset_t>::loop_redblack(
  int threadIdx, int blockIdx, int blockDim, int gridDim) const {

  int64_t index = blockIdx * blockDim + threadIdx;
  int64_t nthreads = N * X * Y * Z;
  offset_t YZ   = Y * Z;
  offset_t XYZ  = X * YZ;
  offset_t n, x, y, z;
  for (offset_t i=index; index < nthreads; index += blockDim*gridDim, i=index)
  {
      // Convert index: linear to sub
      n  = (i/XYZ);
      x  = ((i/YZ) % X);
      y  = ((i/Z)  % Y);
      z  = (i      % Z);
      if ((x+y+z) % 2 == redblack)
        dispatch(x, y, z, n);
  }
}

#else

template <typename scalar_t, typename offset_t> NI_HOST
void RelaxImpl<scalar_t,offset_t>::loop_redblack() const
{
  if (bandwidth == 0)
    return loop_redblack();
  else
    return loop_band();
}

template <typename scalar_t, typename offset_t> NI_HOST
void RelaxImpl<scalar_t,offset_t>::loop_redblack() const
{
  // Parallelize across voxels
  offset_t NXYZ = Z * Y * X * N;
  offset_t XYZ  = Z * Y * X;
  offset_t YZ   = Z * Y;

  for (offset_t redblack = 0; redblack < 2; ++redblack) {
      set_fold(redblack);
      at::parallel_for(0, NXYZ, GRAIN_SIZE, [&](offset_t start, offset_t end) {
        offset_t n, x, y, z;
        for (offset_t i = start; i < end; ++i) {
          // Convert index: linear to sub
          n  = (i/XYZ);
          x  = (i/YZ) % X;
          y  = (i/Z)  % Y;
          z  = i % Z;
          if ((x+y+z) % 2 == redblack)
            dispatch(x, y, z, n);
        }
      });
}

template <typename scalar_t, typename offset_t> NI_HOST
void RelaxImpl<scalar_t,offset_t>::loop_band() const
{
  for (offset_t fold = 0; fold < Fx*Fy*Fz; ++fold) {
      // Index of the fold
      set_fold(fold);
      offset_t YZf   =   Zf * Yf;
      offset_t XYZf  =  YZf * Xf;
      offset_t NXYZf = XYZf * N;

      at::parallel_for(0, NXYZf, GRAIN_SIZE, [&](offset_t start, offset_t end) {
        offset_t n, x, y, z;
        for (offset_t i = start; i < end; ++i) {
          // Convert index: linear to sub
          n  = (i/XYZf);
          x  = ((i/YZf) % Xf) * Fx + fx;
          y  = ((i/Zf)  % Yf) * Fy + fy;
          z  = (i       % Zf) * Fz + fz;
          dispatch(x, y, z, n);
        }
      });
}

#endif

// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
//                             Cholesky
// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

// Cholesky decomposition
// @param[inout]  a: CxC matrix
// @param[out]    p: C vector
template <typename scalar_t, typename offset_t> NI_DEVICE
static void RelaxImpl<scalar_t,offset_t>::cholesky(double a[], double p[])
{
    double sm, sm0;

    sm0  = 1e-40;
    for(offset_t c = 0; c < C; ++c) sm0 += a[c*C+c];
    sm0 *= 1e-7;
    sm0 *= sm0;

    for (offset_t c = 0; c < C; ++c)
    {
        for (b = c; b < C; ++b)
        {
            sm = a[c*C+b];
            for(offset_t d = c-1; d >= 0; --d)
               sm -= a[c*C+d] * a[b*C+d];
            if (c == b)
            {
                sm = MAX(sm, sm0);
                p[c] = std::sqrt(sm);
            }
            else
                a[b*C+c] = sm / p[c];
        }
    }
}

// Cholesky solver (inplace)
// @param[in]    a: CxC matrix
// @param[in]    p: C vector
// @param[inout] x: C vector
template <typename scalar_t, typename offset_t> NI_DEVICE
static void RelaxImpl<scalar_t,offset_t>::cholesky_solve(
    double a[], double p[], double x[])
{
    double sm;

    for (c = 0; c < C; ++c)
    {
        sm = x[c];
        for (cc = c-1; cc >= 0; --cc)
            sm -= a[c*C+cc] * x[cc];
        x[c] = sm / p[c];
    }
    for(c = C-1; c >= 0; --c)
    {
        sm = x[c];
        for(cc = c+1; cc < C; ++cc)
            sm -= a[cc*C+c] * x[cc];
        x[c] = sm / p[c];
    }
}

// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
//                             MatVecAndInvert
// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
// Our relaxation routines perform
//      x += (H + w*I) \ ( g - (H + L) * x )
// Often, g is the gradient, (H+L) is the Hessian where H is easy
// to invert, x is the previous estimate and w is a stabilizing
// constant (in our case, the diagonal of L)
// This subroutines expects
//      v = g - L * x
// and performs
//      v -= H * x
//      x += (H + w) \ v
// (k is a placeholder to store cholesky coefficients)

template <typename scalar_t, typename offset_t> NI_DEVICE
void RelaxImpl<scalar_t,offset_t>::matvec_and_invert_sym(
    scalar_t * x, double * h, double * v, double * k) const {

    for (offset_t c = 0; c < C; ++c) {
        // matvec (part of the forward pass)
        v[c] -= h[c*C+c] * x[c*sol_sC];
        for (offset_t cc = c+1; cc < C; ++cc)
            v[c] -= h[c*C+cc] * x[cc*sol_sC];
        // load diagonal
        h[c+C*c] += w000 * factor[c];
    }
    cholesky(h, k);            // cholesky decomposition
    cholesky_solve(h, k, v);   // solve linear system inplace
    for (offset_t c = 0; c < C; ++c)
        x[c*sol_sC] += val[c];
}

template <typename scalar_t, typename offset_t> NI_DEVICE
void RelaxImpl<scalar_t,offset_t>::matvec_and_invert_diag(
    scalar_t * x, double * h, double * v, double * k) const {

    for (offset_t c = 0; c < C; ++c) {
        v[c] -= h[c] * x[c*sol_sC];
        x[c*sol_sC] += v[c] / (h[c] + w000 * factor[c]);
}

template <typename scalar_t, typename offset_t> NI_DEVICE
void RelaxImpl<scalar_t,offset_t>::matvec_and_invert_const(
    scalar_t * x, double * h, double * v, double * k) const {
    double hh = h[0]
    for (offset_t c = 0; c < C; ++c) {
        v[c] -= hh * x[c*sol_sC];
        x[c*sol_sC] += v[c] / (hh + w000 * factor[c]);
}

template <typename scalar_t, typename offset_t> NI_DEVICE
void RelaxImpl<scalar_t,offset_t>::matvec_and_invert_none(
    scalar_t * x, double * h, double * v, double * k) const {
    double hh = h[0]
    for (offset_t c = 0; c < C; ++c) {
        x[c*sol_sC] += v[c] / (w000 * factor[c]);
}

// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
//                             GetH
// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

template <typename scalar_t, typename offset_t> NI_DEVICE
void RelaxImpl<scalar_t,offset_t>::get_h_sym(
        scalar_t * hessian, double * mat) const {
    for (offset_t c = 0; c < C; ++c, hessian += hes_sC)
        mat[c+C*c] = *hessian;
    for (offset_t c = 0; c < C; ++c)
        for (offset_t cc = c+1; c < C; ++c, hessian += hes_sC)
            mat[c+C*cc] = mat[cc+C*c] = *hessian;
}

template <typename scalar_t, typename offset_t> NI_DEVICE
void RelaxImpl<scalar_t,offset_t>::get_h_diag(
        scalar_t * hessian, double * mat) const {
    for (offset_t c = 0; c < C; ++c, hessian += hes_sC)
        mat[c] = *hessian;
}

template <typename scalar_t, typename offset_t> NI_DEVICE
void RelaxImpl<scalar_t,offset_t>::get_h_const(
        scalar_t * hessian, double * mat) const {
    mat[0] = hessian[0];
}

template <typename scalar_t, typename offset_t> NI_DEVICE
void RelaxImpl<scalar_t,offset_t>::get_h_none(
        scalar_t * hessian, double * mat) const {}

/* ================================================================== */
/*                                 3D                                 */
/* ================================================================== */

#define GET_COORD1 \
  offset_t x0  = x-1, y0  = y-1, z0  = z-1, x1  = x+1, y1  = y+1, z1  = z+1;
#define GET_COORD2 \
  offset_t x00 = x-2, y00 = y-2, z00 = z-2, x11 = x+2, y11 = y+2, z11 = z+2;
#define GET_SIGN1 \
  int8_t  sx0  = bound::sign(bound0, x0,  X); \
  int8_t  sy0  = bound::sign(bound1, y0,  Y); \
  int8_t  sz0  = bound::sign(bound2, z0,  Z); \
  int8_t  sx1  = bound::sign(bound0, x1,  X); \
  int8_t  sy1  = bound::sign(bound1, y1,  Y); \
  int8_t  sz1  = bound::sign(bound2, z1,  Z);
#define GET_SIGN2 \
  int8_t  sx00 = bound::sign(bound0, x00, X); \
  int8_t  sy00 = bound::sign(bound1, y00, Y); \
  int8_t  sz00 = bound::sign(bound2, z00, Z); \
  int8_t  sx11 = bound::sign(bound0, x11, X); \
  int8_t  sy11 = bound::sign(bound1, y11, Y); \
  int8_t  sz11 = bound::sign(bound2, z11, Z);
#define GET_WARP1 \
  x0  = (bound::index(bound0, x0,  X) - x) * sol_sX; \
  y0  = (bound::index(bound1, y0,  Y) - y) * sol_sY; \
  z0  = (bound::index(bound2, z0,  Z) - z) * sol_sZ; \
  x1  = (bound::index(bound0, x1,  X) - x) * sol_sX; \
  y1  = (bound::index(bound1, y1,  Y) - y) * sol_sY; \
  z1  = (bound::index(bound2, z1,  Z) - z) * sol_sZ;
#define GET_WARP2 \
  x00 = (bound::index(bound0, x00, X) - x) * sol_sX; \
  y00 = (bound::index(bound1, y00, Y) - y) * sol_sY; \
  z00 = (bound::index(bound2, z00, Z) - z) * sol_sZ; \
  x11 = (bound::index(bound0, x11, X) - x) * sol_sX; \
  y11 = (bound::index(bound1, y11, Y) - y) * sol_sY; \
  z11 = (bound::index(bound2, z11, Z) - z) * sol_sZ;
#define GET_POINTERS3 \
  scalar_t *sol0 = sol_ptr + (x*sol_sX + y*sol_sY + z*sol_sZ + n*sol_sN);  \
  scalar_t *sol1 = sol0 + sol_sC, *sol2 = sol0 + 2 * sol_sC;               \
  scalar_t *grd0 = grd_ptr + (x*grd_sX + y*grd_sY + z*grd_sZ + n*grd_sN);  \
  scalar_t *grd1 = grd0 + grd_sC, *grd2 = grd0 + 2 * grd_sC;
#define GET_HESS_POINTERS3 \
  scalar_t *hes00 = hes_ptr + (x*hes_sX + y*hes_sY + z*hes_sZ + n*hes_sN); \
  scalar_t *hes11 = hes00 +     hes_sC, \
           *hes22 = hes00 + 2 * hes_sC, \
           *hes01 = hes00 + 3 * hes_sC, \
           *hes02 = hes00 + 4 * hes_sC, \
           *hes12 = hes00 + 5 * hes_sC;

template <typename scalar_t, typename offset_t> NI_DEVICE
void RelaxImpl<scalar_t,offset_t>::relax3d_all(offset_t x, offset_t y, offset_t z, offset_t n) const {

  // WE KNOW WE ARE IN GRID MODE -> 3 channels //

  GET_COORD1
  GET_COORD2

  // Sign (/!\ compute sign before warping indices)
  GET_SIGN1
  GET_SIGN2

  // Warp indices
  GET_WARP1
  GET_WARP2

  GET_POINTERS3

  double val0, val1, val2;

  // For numerical stability, we subtract the center value before convolving.
  // We define a lambda function for ease.

  {
      scalar_t c = *sol0;  // no need to use `get` -> we know we are in the FOV
      auto get0 = [c](scalar_t * x, offset_t o, int8_t s)
      {
        return bound::get(x, o, s) - c;
      };

      val0 = (*grd0) -  (wx100*(get0(inp0, x0, sx0) + get0(inp0, x1, sx1))
                       + wx010*(get0(inp0, y0, sy0) + get0(inp0, y1, sy1))
                       + wx001*(get0(inp0, z0, sz0) + get0(inp0, z1, sz1))
                       + w2   *( bound::get(inp1, x1+y0, sx1*sy0) - bound::get(inp1, x1+y1, sx1*sy1)
                               + bound::get(inp1, x0+y1, sx0*sy1) - bound::get(inp1, x0+y0, sx0*sy0)
                               + bound::get(inp2, x1+z0, sx1*sz0) - bound::get(inp2, x1+z1, sx1*sz1)
                               + bound::get(inp2, x0+z1, sx0*sz1) - bound::get(inp2, x0+z0, sx0*sz0))
                        + (absolute*c
                        +  w110*(get0(inp0, x0+y0, sx0*sy0) + get0(inp0, x1+y0, sx1*sy0) +
                                 get0(inp0, x0+y1, sx1*sy1) + get0(inp0, x1+y1, sx1*sy1))
                        +  w101*(get0(inp0, x0+z0, sx0*sz0) + get0(inp0, x1+z0, sx1*sz0) +
                                 get0(inp0, x0+z1, sx1*sz1) + get0(inp0, x1+z1, sx1*sz1))
                        +  w011*(get0(inp0, y0+z0, sy0*sz0) + get0(inp0, y1+z0, sy1*sz0) +
                                 get0(inp0, y0+z1, sy1*sz1) + get0(inp0, y1+z1, sy1*sz1))
                        +  w200*(get0(inp0, x00, sx00) + get0(inp0, x11, sx11))
                        +  w020*(get0(inp0, y00, sy00) + get0(inp0, y11, sy11))
                        +  w002*(get0(inp0, z00, sz00) + get0(inp0, z11, sz11)))*f0);
  }

  {
      scalar_t c = *inp1;
      auto get1 = [c](scalar_t * x, offset_t o, int8_t s)
      {
        return bound::get(x, o, s) - c;
      };

      val1 = (*grd1) -  (wy100*(get1(inp1, x0, sx0) + get1(inp1, x1, sx1))
                       + wy010*(get1(inp1, y0, sy0) + get1(inp1, y1, sy1))
                       + wy001*(get1(inp1, z0, sz0) + get1(inp1, z1, sz1))
                       + w2   *( bound::get(inp0, y1+x0, sy1*sx0) - bound::get(inp0, y1+x1, sy1*sx1)
                               + bound::get(inp0, y0+x1, sy0*sx1) - bound::get(inp0, y0+x0, sy0*sx0)
                               + bound::get(inp2, y1+z0, sy1*sz0) - bound::get(inp2, y1+z1, sy1*sz1)
                               + bound::get(inp2, y0+z1, sy0*sz1) - bound::get(inp2, y0+z0, sy0*sz0))
                        + (absolute*c
                        +  w110*(get1(inp1, x0+y0, sx0*sy0) + get1(inp1, x1+y0, sx1*sy0) +
                                 get1(inp1, x0+y1, sx1*sy1) + get1(inp1, x1+y1, sx1*sy1))
                        +  w101*(get1(inp1, x0+z0, sx0*sz0) + get1(inp1, x1+z0, sx1*sz0) +
                                 get1(inp1, x0+z1, sx1*sz1) + get1(inp1, x1+z1, sx1*sz1))
                        +  w011*(get1(inp1, y0+z0, sy0*sz0) + get1(inp1, y1+z0, sy1*sz0) +
                                 get1(inp1, y0+z1, sy1*sz1) + get1(inp1, y1+z1, sy1*sz1))
                        +  w200*(get1(inp1, x00, sx00) + get1(inp1, x11, sx11))
                        +  w020*(get1(inp1, y00, sy00) + get1(inp1, y11, sy11))
                        +  w002*(get1(inp1, z00, sz00) + get1(inp1, z11, sz11)))*f1);
  }

  {
      scalar_t c = *inp2;
      auto get2 = [c](scalar_t * x, offset_t o, int8_t s)
      {
        return bound::get(x, o, s) - c;
      };

      val2 = (*grd2) -  (wy100*(get2(inp2, x0, sx0) + get2(inp2, x1, sx1))
                       + wy010*(get2(inp2, y0, sy0) + get2(inp2, y1, sy1))
                       + wy001*(get2(inp2, z0, sz0) + get2(inp2, z1, sz1))
                       + w2   *( bound::get(inp0, z1+x0, sz1*sx0) - bound::get(inp0, z1+x1, sz1*sx1)
                               + bound::get(inp0, z0+x1, sz0*sx1) - bound::get(inp0, z0+x0, sz0*sx0)
                               + bound::get(inp1, z1+y0, sz1*sy0) - bound::get(inp1, z1+y1, sz1*sy1)
                               + bound::get(inp1, z0+y1, sz0*sy1) - bound::get(inp1, z0+y0, sz0*sy0))
                        + (absolute*c
                        +  w110*(get2(inp2, x0+y0, sx0*sy0) + get2(inp2, x1+y0, sx1*sy0) +
                                 get2(inp2, x0+y1, sx1*sy1) + get2(inp2, x1+y1, sx1*sy1))
                        +  w101*(get2(inp2, x0+z0, sx0*sz0) + get2(inp2, x1+z0, sx1*sz0) +
                                 get2(inp2, x0+z1, sx1*sz1) + get2(inp2, x1+z1, sx1*sz1))
                        +  w011*(get2(inp2, y0+z0, sy0*sz0) + get2(inp2, y1+z0, sy1*sz0) +
                                 get2(inp2, y0+z1, sy1*sz1) + get2(inp2, y1+z1, sy1*sz1))
                        +  w200*(get2(inp2, x00, sx00) + get2(inp2, x11, sx11))
                        +  w020*(get2(inp2, y00, sy00) + get2(inp2, y11, sy11))
                        +  w002*(get2(inp2, z00, sz00) + get2(inp2, z11, sz11)))*f2);
  }

  // inversion
  if (hes_ptr)
  {
    GET_HESS_POINTERS3
    if (CC == 1) // constant
    {
        double h = *hes00, s0 = *sol0, s1 = *sol1, s2 = *sol2;

        // matvec
        val0 -= h * s0;
        val1 -= h * s1;
        val2 -= h * s2;

        // solve
        (*sol0) += val0 / (h * OnePlusTiny + wx000);
        (*sol1) += val1 / (h * OnePlusTiny + wy000);
        (*sol2) += val2 / (h * OnePlusTiny + wz000);
    }
    }
    else if (CC = C) // diagonal
    {
        double h00 = *hes00, h11 = *hes11, h22 = *hes22,
               s0  = *sol0,  s1  = *sol1,  s2  = *sol2;

        // matvec
        val0 -= h00 * s0;
        val1 -= h11 * s1;
        val2 -= h22 * s2;

        // solve
        (*sol0) += val0 / (h00 * OnePlusTiny + wx000);
        (*sol1) += val1 / (h11 * OnePlusTiny + wy000);
        (*sol2) += val2 / (h22 * OnePlusTiny + wz000);
    }
    else // symmetric
    {
        double h00 = *hes00, h11 = *hes11, h22 = *hes22,
               h01 = *hes01, h02 = *hes02, h12 = *hes12,
               s0  = *sol0,  s1  = *sol1,  s2  = *sol2,
               idt;

        // matvec
        val0 -= (h00*s0 + h01*s1 + h02*s2);
        val1 -= (h01*s0 + h11*s1 + h12*s2);
        val2 -= (h02*s0 + h12*s1 + h22*s2);

        // solve
        h00  = h00 * OnePlusTiny + wx000;
        h11  = h11 * OnePlusTiny + wy000;
        h22  = h22 * OnePlusTiny + wz000;
        idt  = 1.0/(h00*h11*h22 - h00*h12*h12 - h11*h02*h02 - h22*h01*h01 + 2*h01*h02*h12);
        (*sol0) += idt*(val0*(h11*h22-h12*h12) + val1*(h02*h12-h01*h22) + val2*(h01*h12-h02*h11));
        (*sol1) += idt*(val0*(h02*h12-h01*h22) + val1*(h00*h22-h02*h02) + val2*(h01*axz-h00*h12));
        (*sol2) += idt*(val0*(h01*h12-h02*h11) + val1*(h01*h02-h00*h12) + val2*(h00*h11-h01*h01));
    }
  }
  else
  {
    (*sol0) += val0 / wx000;
    (*sol1) += val1 / wy000;
    (*sol2) += val2 / wz000;
  }
}


template <typename scalar_t, typename offset_t> NI_DEVICE
void RelaxImpl<scalar_t,offset_t>::relax3d_lame(offset_t x, offset_t y, offset_t z, offset_t n) const {

  // WE KNOW WE ARE IN GRID MODE -> 3 channels //

  GET_COORD1
  GET_COORD2

  // Sign (/!\ compute sign before warping indices)
  GET_SIGN1
  GET_SIGN2

  // Warp indices
  GET_WARP1
  GET_WARP2

  GET_POINTERS3

  double val0, val1, val2;

  // For numerical stability, we subtract the center value before convolving.
  // We define a lambda function for ease.

  {
      scalar_t c = *sol0;  // no need to use `get` -> we know we are in the FOV
      auto get0 = [c](scalar_t * x, offset_t o, int8_t s)
      {
        return bound::get(x, o, s) - c;
      };

      val0 = (*grd0) -  (wx100*(get0(inp0, x0, sx0) + get0(inp0, x1, sx1))
                       + wx010*(get0(inp0, y0, sy0) + get0(inp0, y1, sy1))
                       + wx001*(get0(inp0, z0, sz0) + get0(inp0, z1, sz1))
                       + w2   *( bound::get(inp1, x1+y0, sx1*sy0) - bound::get(inp1, x1+y1, sx1*sy1)
                               + bound::get(inp1, x0+y1, sx0*sy1) - bound::get(inp1, x0+y0, sx0*sy0)
                               + bound::get(inp2, x1+z0, sx1*sz0) - bound::get(inp2, x1+z1, sx1*sz1)
                               + bound::get(inp2, x0+z1, sx0*sz1) - bound::get(inp2, x0+z0, sx0*sz0)))*f0);
  }

  {
      scalar_t c = *inp1;
      auto get1 = [c](scalar_t * x, offset_t o, int8_t s)
      {
        return bound::get(x, o, s) - c;
      };

      val1 = (*grd1) -  (wy100*(get1(inp1, x0, sx0) + get1(inp1, x1, sx1))
                       + wy010*(get1(inp1, y0, sy0) + get1(inp1, y1, sy1))
                       + wy001*(get1(inp1, z0, sz0) + get1(inp1, z1, sz1))
                       + w2   *( bound::get(inp0, y1+x0, sy1*sx0) - bound::get(inp0, y1+x1, sy1*sx1)
                               + bound::get(inp0, y0+x1, sy0*sx1) - bound::get(inp0, y0+x0, sy0*sx0)
                               + bound::get(inp2, y1+z0, sy1*sz0) - bound::get(inp2, y1+z1, sy1*sz1)
                               + bound::get(inp2, y0+z1, sy0*sz1) - bound::get(inp2, y0+z0, sy0*sz0)))*f1);
  }

  {
      scalar_t c = *inp2;
      auto get2 = [c](scalar_t * x, offset_t o, int8_t s)
      {
        return bound::get(x, o, s) - c;
      };

      val2 = (*grd2) -  (wy100*(get2(inp2, x0, sx0) + get2(inp2, x1, sx1))
                       + wy010*(get2(inp2, y0, sy0) + get2(inp2, y1, sy1))
                       + wy001*(get2(inp2, z0, sz0) + get2(inp2, z1, sz1))
                       + w2   *( bound::get(inp0, z1+x0, sz1*sx0) - bound::get(inp0, z1+x1, sz1*sx1)
                               + bound::get(inp0, z0+x1, sz0*sx1) - bound::get(inp0, z0+x0, sz0*sx0)
                               + bound::get(inp1, z1+y0, sz1*sy0) - bound::get(inp1, z1+y1, sz1*sy1)
                               + bound::get(inp1, z0+y1, sz0*sy1) - bound::get(inp1, z0+y0, sz0*sy0)))*f2);
  }

  // inversion
  if (hes_ptr)
  {
    GET_HESS_POINTERS3
    if (CC == 1) // constant
    {
        double h = *hes00, s0 = *sol0, s1 = *sol1, s2 = *sol2;

        // matvec
        val0 -= h * s0;
        val1 -= h * s1;
        val2 -= h * s2;

        // solve
        (*sol0) += val0 / (h * OnePlusTiny + wx000);
        (*sol1) += val1 / (h * OnePlusTiny + wy000);
        (*sol2) += val2 / (h * OnePlusTiny + wz000);
    }
    }
    else if (CC = C) // diagonal
    {
        double h00 = *hes00, h11 = *hes11, h22 = *hes22,
               s0  = *sol0,  s1  = *sol1,  s2  = *sol2;

        // matvec
        val0 -= h00 * s0;
        val1 -= h11 * s1;
        val2 -= h22 * s2;

        // solve
        (*sol0) += val0 / (h00 * OnePlusTiny + wx000);
        (*sol1) += val1 / (h11 * OnePlusTiny + wy000);
        (*sol2) += val2 / (h22 * OnePlusTiny + wz000);
    }
    else // symmetric
    {
        double h00 = *hes00, h11 = *hes11, h22 = *hes22,
               h01 = *hes01, h02 = *hes02, h12 = *hes12,
               s0  = *sol0,  s1  = *sol1,  s2  = *sol2,
               idt;

        // matvec
        val0 -= (h00*s0 + h01*s1 + h02*s2);
        val1 -= (h01*s0 + h11*s1 + h12*s2);
        val2 -= (h02*s0 + h12*s1 + h22*s2);

        // solve
        h00  = h00 * OnePlusTiny + wx000;
        h11  = h11 * OnePlusTiny + wy000;
        h22  = h22 * OnePlusTiny + wz000;
        idt  = 1.0/(h00*h11*h22 - h00*h12*h12 - h11*h02*h02 - h22*h01*h01 + 2*h01*h02*h12);
        (*sol0) += idt*(val0*(h11*h22-h12*h12) + val1*(h02*h12-h01*h22) + val2*(h01*h12-h02*h11));
        (*sol1) += idt*(val0*(h02*h12-h01*h22) + val1*(h00*h22-h02*h02) + val2*(h01*axz-h00*h12));
        (*sol2) += idt*(val0*(h01*h12-h02*h11) + val1*(h01*h02-h00*h12) + val2*(h00*h11-h01*h01));
    }
  }
  else
  {
    (*sol0) += val0 / wx000;
    (*sol1) += val1 / wy000;
    (*sol2) += val2 / wz000;
  }
}


template <typename scalar_t, typename offset_t> NI_DEVICE
void RelaxImpl<scalar_t,offset_t>::relax3d_bending(offset_t x, offset_t y, offset_t z, offset_t n) const {

  GET_COORD1
  GET_COORD2
  GET_SIGN1
  GET_SIGN2
  GET_WARP1
  GET_WARP2

  offset_t index_sol = x*sol_sX + y*sol_sY + z*sol_sZ + n*sol_sN;
  offset_t index_grd = x*grd_sX + y*grd_sY + z*grd_sZ + n*grd_sN;
  offset_t index_hes = x*hes_sX + y*hes_sY + z*hes_sZ + n*hes_sN;
  scalar_t * sol_ = sol_ptr + index_sol;
  scalar_t * grd_ = grd_ptr + index_grd;
  scalar_t * hes_ = hes_ptr + index_hes;

  double val[NI_MAX_NUM_CHANNELS], h[NI_MAX_NUM_CHANNELS*NI_MAX_NUM_CHANNELS],
         chol[NI_MAX_NUM_CHANNELS];

  for (offset_t c = 0, scalar_t *sol = sol_, scalar_t *grd = grd_;
       c < C; ++c, sol += sol_sC, grd += grd_sC)
  {
      scalar_t center = *sol;
      auto get2 = [center](scalar_t * x, offset_t o, int8_t s)
      {
        return bound::get(x, o, s) - center;
      };

      val[c] = grd[c] - (absolute*center
                     +  w100*(get2(sol, x0, sx0) + get2(sol, x1, sx1))
                     +  w010*(get2(sol, y0, sy0) + get2(sol, y1, sy1))
                     +  w001*(get2(sol, z0, sz0) + get2(sol, z1, sz1))
                     +  w110*(get2(sol, x0+y0, sx0*sy0) + get2(sol, x1+y0, sx1*sy0) +
                              get2(sol, x0+y1, sx1*sy1) + get2(sol, x1+y1, sx1*sy1))
                     +  w101*(get2(sol, x0+z0, sx0*sz0) + get2(sol, x1+z0, sx1*sz0) +
                              get2(sol, x0+z1, sx1*sz1) + get2(sol, x1+z1, sx1*sz1))
                     +  w011*(get2(sol, y0+z0, sy0*sz0) + get2(sol, y1+z0, sy1*sz0) +
                              get2(sol, y0+z1, sy1*sz1) + get2(sol, y1+z1, sy1*sz1))
                     +  w200*(get2(sol, x00, sx00) + get2(sol, x11, sx11))
                     +  w020*(get2(sol, y00, sy00) + get2(sol, y11, sy11))
                     +  w002*(get2(sol, z00, sz00) + get2(sol, z11, sz11)))*factor[c];
  }

  // invert
  matvec_and_invert(sol_, h, val);
}


template <typename scalar_t, typename offset_t> NI_DEVICE
void RelaxImpl<scalar_t,offset_t>::relax3d_membrane(offset_t x, offset_t y, offset_t z, offset_t n) const {

  offset_t x0 = x-1, y0 = y-1, z0 = z-1, x1 = x+1, y1 = y+1, z1 = z+1;

  // Sign (/!\ compute sign before warping indices)
  int8_t  sx0  = bound::sign(bound0, x0,  X);
  int8_t  sy0  = bound::sign(bound1, y0,  Y);
  int8_t  sz0  = bound::sign(bound2, z0,  Z);
  int8_t  sx1  = bound::sign(bound0, x1,  X);
  int8_t  sy1  = bound::sign(bound1, y1,  Y);
  int8_t  sz1  = bound::sign(bound2, z1,  Z);

  // Warp indices
  x0  = (bound::index(bound0, x0,  X) - x) * inp_sX;
  y0  = (bound::index(bound1, y0,  Y) - y) * inp_sY;
  z0  = (bound::index(bound2, z0,  Z) - z) * inp_sZ;
  x1  = (bound::index(bound0, x1,  X) - x) * inp_sX;
  y1  = (bound::index(bound1, y1,  Y) - y) * inp_sY;
  z1  = (bound::index(bound2, z1,  Z) - z) * inp_sZ;

  scalar_t * out_ = out_ptr + (x*out_sX + y*out_sY + z*out_sZ);
  scalar_t * inp_ = inp_ptr + (x*inp_sX + y*inp_sY + z*inp_sZ);

  for (offset_t c = 0; c < C; ++c, out_ += out_sC, inp_ += inp_sC)
  {
      double f = factor[MIN(c, factor.size()-1)];

      // For numerical stability, we subtract the center value before convolving.
      // We define a lambda function for ease.
      scalar_t center = *inp_;  // no need to use `get` -> we know we are in the FOV
      auto get2 = [center](scalar_t * x, offset_t o, int8_t s)
      {
        return bound::get(x, o, s) - center;
      };

      *out_ = (scalar_t)((absolute*center
                     +  w100*(get2(inp_, x0, sx0) + get2(inp_, x1, sx1))
                     +  w010*(get2(inp_, y0, sy0) + get2(inp_, y1, sy1))
                     +  w001*(get2(inp_, z0, sz0) + get2(inp_, z1, sz1)))*f);
  }

}


template <typename scalar_t, typename offset_t> NI_DEVICE
void RelaxImpl<scalar_t,offset_t>::relax3d_absolute(offset_t x, offset_t y, offset_t z, offset_t n) const {

  offset_t out_ = x*out_sX + y*out_sY + z*out_sZ;
  offset_t inp_ = x*inp_sX + y*inp_sY + z*inp_sZ;

  for (offset_t c = 0; c < C; ++c, out_ += out_sC, inp_ += inp_sC)
  {
      out_ptr[out_] = (scalar_t)(absolute*inp_ptr[inp_]*factor[c]);
  }

}


template <typename scalar_t, typename offset_t> NI_DEVICE
void RelaxImpl<scalar_t,offset_t>::relax3d_rls_membrane(offset_t x, offset_t y, offset_t z, offset_t n) const {

  offset_t x0 = x-1, y0 = y-1, z0 = z-1, x1 = x+1, y1 = y+1, z1 = z+1;

  // Sign (/!\ compute sign before warping indices)
  int8_t  sx0  = bound::sign(bound0, x0,  X);
  int8_t  sy0  = bound::sign(bound1, y0,  Y);
  int8_t  sz0  = bound::sign(bound2, z0,  Z);
  int8_t  sx1  = bound::sign(bound0, x1,  X);
  int8_t  sy1  = bound::sign(bound1, y1,  Y);
  int8_t  sz1  = bound::sign(bound2, z1,  Z);

  // Warp indices
  x0  = bound::index(bound0, x0,  X) - x;
  y0  = bound::index(bound1, y0,  Y) - y;
  z0  = bound::index(bound2, z0,  Z) - z;
  x1  = bound::index(bound0, x1,  X) - x;
  y1  = bound::index(bound1, y1,  Y) - y;
  z1  = bound::index(bound2, z1,  Z) - z;

  scalar_t * out_ = out_ptr + (x*out_sX + y*out_sY + z*out_sZ);
  scalar_t * inp_ = inp_ptr + (x*inp_sX + y*inp_sY + z*inp_sZ);
  scalar_t * wgt_ = wgt_ptr + (x*wgt_sX + y*wgt_sY + z*wgt_sZ);

  for (offset_t c = 0; c < C;
       ++c, out_ += out_sC, inp_ += inp_sC, wgt_ += wgt_sC)
  {
      double f = factor[c];

      // The convolution kernel is obtained by convolving the weight map
      scalar_t wcenter = *wgt_;
      double w1m00 = w100*(wcenter + bound::get(wgt_, x0 * wgt_sX, sx0));
      double w1p00 = w100*(wcenter + bound::get(wgt_, x1 * wgt_sX, sx1));
      double w01m0 = w010*(wcenter + bound::get(wgt_, y0 * wgt_sY, sy0));
      double w01p0 = w010*(wcenter + bound::get(wgt_, y1 * wgt_sY, sy1));
      double w001m = w001*(wcenter + bound::get(wgt_, z0 * wgt_sZ, sz0));
      double w001p = w001*(wcenter + bound::get(wgt_, z1 * wgt_sZ, sz1));

      // For numerical stability, we subtract the center value before convolving.
      // We define a lambda function for ease.
      scalar_t center = *inp_;  // no need to use `get` -> we know we are in the FOV
      auto get2 = [center](scalar_t * x, offset_t o, int8_t s)
      {
        return bound::get(x, o, s) - center;
      };

      *out_ = (scalar_t)((absolute*wcenter*center
                     + w1m00*get2(inp_, x0 * wgt_sX, sx0)
                     + w1p00*get2(inp_, x1 * wgt_sX, sx1)
                     + w01m0*get2(inp_, y0 * wgt_sY, sy0)
                     + w01p0*get2(inp_, y1 * wgt_sY, sy1)
                     + w001m*get2(inp_, z0 * wgt_sZ, sz0)
                     + w001p*get2(inp_, z1 * wgt_sZ, sz1))*f);
  }

}


template <typename scalar_t, typename offset_t> NI_DEVICE
void RelaxImpl<scalar_t,offset_t>::relax3d_rls_absolute(offset_t x, offset_t y, offset_t z, offset_t n) const {

  offset_t out_ = x*out_sX + y*out_sY + z*out_sZ;
  offset_t inp_ = x*inp_sX + y*inp_sY + z*inp_sZ;
  offset_t wgt_ = x*wgt_sX + y*wgt_sY + z*wgt_sZ;

  for (offset_t c = 0; c < C;
       ++c, out_ += out_sC, inp_ += inp_sC, wgt_ += wgt_sC)
  {
      out_ptr[out_] = (scalar_t)(absolute*inp_ptr[inp_]*wgt_ptr[wgt_]*factor[c]);
  }

}


template <typename scalar_t, typename offset_t> NI_DEVICE
void RelaxImpl<scalar_t,offset_t>::relax2d_lame(offset_t x, offset_t y, offset_t z, offset_t n) const {}
template <typename scalar_t, typename offset_t> NI_DEVICE
void RelaxImpl<scalar_t,offset_t>::relax2d_bending(offset_t x, offset_t y, offset_t z, offset_t n) const {}
template <typename scalar_t, typename offset_t> NI_DEVICE
void RelaxImpl<scalar_t,offset_t>::relax2d_membrane(offset_t x, offset_t y, offset_t z, offset_t n) const {}
template <typename scalar_t, typename offset_t> NI_DEVICE
void RelaxImpl<scalar_t,offset_t>::relax2d_absolute(offset_t x, offset_t y, offset_t z, offset_t n) const {}
template <typename scalar_t, typename offset_t> NI_DEVICE
void RelaxImpl<scalar_t,offset_t>::relax2d_rls_membrane(offset_t x, offset_t y, offset_t z, offset_t n) const {}
template <typename scalar_t, typename offset_t> NI_DEVICE
void RelaxImpl<scalar_t,offset_t>::relax2d_rls_absolute(offset_t x, offset_t y, offset_t z, offset_t n) const {}


template <typename scalar_t, typename offset_t> NI_DEVICE
void RelaxImpl<scalar_t,offset_t>::relax1d_lame(offset_t x, offset_t y, offset_t z, offset_t n) const {}
template <typename scalar_t, typename offset_t> NI_DEVICE
void RelaxImpl<scalar_t,offset_t>::relax1d_bending(offset_t x, offset_t y, offset_t z, offset_t n) const {}
template <typename scalar_t, typename offset_t> NI_DEVICE
void RelaxImpl<scalar_t,offset_t>::relax1d_membrane(offset_t x, offset_t y, offset_t z, offset_t n) const {}
template <typename scalar_t, typename offset_t> NI_DEVICE
void RelaxImpl<scalar_t,offset_t>::relax1d_absolute(offset_t x, offset_t y, offset_t z, offset_t n) const {}
template <typename scalar_t, typename offset_t> NI_DEVICE
void RelaxImpl<scalar_t,offset_t>::relax1d_rls_membrane(offset_t x, offset_t y, offset_t z, offset_t n) const {}
template <typename scalar_t, typename offset_t> NI_DEVICE
void RelaxImpl<scalar_t,offset_t>::relax1d_rls_absolute(offset_t x, offset_t y, offset_t z, offset_t n) const {}

template <typename scalar_t, typename offset_t> NI_DEVICE
void RelaxImpl<scalar_t,offset_t>::solve1d(offset_t x, offset_t y, offset_t z, offset_t n) const {}
template <typename scalar_t, typename offset_t> NI_DEVICE
void RelaxImpl<scalar_t,offset_t>::solve2d(offset_t x, offset_t y, offset_t z, offset_t n) const {}
template <typename scalar_t, typename offset_t> NI_DEVICE
void RelaxImpl<scalar_t,offset_t>::solve3d(offset_t x, offset_t y, offset_t z, offset_t n) const {}



// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
//                  CUDA KERNEL (MUST BE OUT OF CLASS)
// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

#ifdef __CUDACC__
// CUDA Kernel
template <typename scalar_t, typename offset_t>
C10_LAUNCH_BOUNDS_1(1024)
__global__ void regulariser_kernel(RelaxImpl<scalar_t,offset_t> f) {
  f.loop(threadIdx.x, blockIdx.x, blockDim.x, gridDim.x);
}
#endif

NI_HOST std::tuple<Tensor, Tensor, Tensor>
prepare_tensors(const Tensor & gradient,
                Tensor hessian, Tensor solution, Tensor weight)
{
    int64_t dim = gradient.dim() - 2;
    int64_t N = gradient.size(0);
    int64_t C = gradient.size(1);
    int64_t X = gradient.size(2);
    int64_t Y = dim > 1 ? gradient.size(3) : 1L;
    int64_t Z = dim > 2 ? gradient.size(4) : 1L;

    if !((solution.defined() && solution.numel() > 0))
      solution = at::zeros_like(gradient);
    if (solution.size() != gradient.size())
      throw std::invalid_argument("Initial solution must have the same shape as the gradient");

    if (hessian.defined() && hessian.numel() > 0)
    {
      while (hessian.dim() < gradient.dim())
        hessian = hessian.unsqueeze(0);
      int64_t CC = hessian.size(1);
      auto hshape = (dim == 1 ? {N, CC, X} : dim == 2 ? {N, CC, X, Y} : {N, CC, C, Y, Z});
      hessian = hessian.expand(hshape);
    }

    if (weight.defined() && weight.numel() > 0)
    {
      while (weight.dim() < gradient.dim())
        weight = weight.unsqueeze(0);
      weight = weight.expand(gradient.size());
    }
}

} // namespace

// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
//                    FUNCTIONAL FORM WITH DISPATCH
// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

#ifdef __CUDACC__

// ~~~ CUDA ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

NI_HOST Tensor relax(
  Tensor hessian, const Tensor& gradient, Tensor solution, Tensor weight, bool grid,
  double absolute, double membrane, double bending, double lame_shear, double lame_div,
  ArrayRef<double> factor, ArrayRef<double> voxel_size, BoundVectorRef bound)
{
  auto tensors = prepare_tensors(gradient, hessian, solution, weight);
  hessian  = std::get<0>(tensors);
  solution = std::get<1>(tensors);
  weight   = std::get<2>(tensors);

  RelaxAllocator info(input.dim()-2, grid, absolute, membrane, bending,
                      lame_shear, lame_div, factor, voxel_size, bound);
  info.ioset(input, weight);

  return AT_DISPATCH_FLOATING_TYPES_AND_HALF(input.scalar_type(), "relax", [&] {
    if (info.canUse32BitIndexMath())
    {
      RelaxImpl<scalar_t, int32_t> algo(info);
      for (offset_t fold = 0; fold < algo.foldcount(); ++fold) {
          algo.set_fold(fold);
          relax_kernel<<<GET_BLOCKS(algo.voxcountfold()), CUDA_NUM_THREADS, 0,
                         at::cuda::getCurrentCUDAStream()>>>(algo);
      }
      return algo.output;
    }
    else
    {
      RelaxImpl<scalar_t, int64_t> algo(info);
      for (offset_t fold = 0; fold < algo.foldcount(); ++fold) {
          algo.set_fold(fold);
          relax_kernel<<<GET_BLOCKS(algo.voxcountfold()), CUDA_NUM_THREADS, 0,
                         at::cuda::getCurrentCUDAStream()>>>(algo);
      }
      return algo.output;
    }
  });
}

#else

// ~~~ CPU ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

NI_HOST Tensor relax(
  Tensor hessian, const Tensor& gradient, Tensor solution, Tensor weight, bool grid,
  double absolute, double membrane, double bending, double lame_shear, double lame_div,
  ArrayRef<double> factor, ArrayRef<double> voxel_size, BoundVectorRef bound)
{
  auto tensors = prepare_tensors(gradient, hessian, solution, weight);
  hessian  = std::get<0>(tensors);
  solution = std::get<1>(tensors);
  weight   = std::get<2>(tensors);

  RelaxAllocator info(input.dim()-2, grid, absolute, membrane, bending,
                      lame_shear, lame_div, factor, voxel_size, bound);
  info.ioset(input, weight);

  return AT_DISPATCH_FLOATING_TYPES(input.scalar_type(), "relax", [&] {
    RelaxImpl<scalar_t, int64_t> algo(info);
    algo.loop();
    return algo.output;
  });
}

#endif // __CUDACC__

} // namespace <device>

// ~~~ NOT IMPLEMENTED ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

namespace notimplemented {

NI_HOST Tensor relax(
  Tensor hessian, const Tensor& gradient, Tensor solution, Tensor weight, bool grid,
  double absolute, double membrane, double bending, double lame_shear, double lame_div,
  ArrayRef<double> factor, ArrayRef<double> voxel_size, BoundVectorRef bound)
{
  throw std::logic_error("Function not implemented for this device.");
}


} // namespace notimplemented

} // namespace ni
